{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2c09de",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "60f748fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import seaborn as sns \n",
    "from pymongo import MongoClient\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c47ffb",
   "metadata": {},
   "source": [
    "## Initialisation du Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1fc5e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpYXQiOjE3MDg3MDMwNjcsImV4cCI6MTcwODcwNjY2Nywicm9sZXMiOlsiUk9MRV9BUEkiXSwidXNlcm5hbWUiOiJtb3VzdGFwaGFfZmFsbCJ9.OJsKdH5Y3GZd1j6pFxa79b4GPyGdSgtaopdKaIDpkN_4YmS2I2dnMZncqH7Mny2afszGVLDrSuUBm4unC9tVXZXiouh_vG5ricB0DvkaCgBMy5kSebWgZytsmuxK7Heh8Hhl8N3DxfPL_sLqpkBKWSfzxywN__8I0mh_vV4oxSNR-2AYCX5FWgnhDuXkCyS39FDtP173Nj79elapAI8eZDcp4TyHY-H2SxFBe88YZFf1_BFRw2Mux5Z13r0MquO_OiSBVLBynjN4unYFbsgqYBSiZJvvPuOL8ob2Pl3AQfn0211N0din7AuFWRh0gFIrQT4sv6KbDmulPEG2KU95NA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16dac03",
   "metadata": {},
   "source": [
    "## Fonctions Secondaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2ed58",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef57299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_atmo_data(api_key, id_data, params):\n",
    "    \"\"\"\n",
    "    Fetches data from AtmoData API.\n",
    "    \n",
    "    Args:\n",
    "    - api_key (str): API key for authentication.\n",
    "    - id_data (int): Identifier of the data.\n",
    "    - params (dict): Parameters for the query.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: JSON response from the API converted into DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construction de l'URL avec l'identifiant de la donnée\n",
    "    url = f\"https://admindata.atmo-france.org/api/data/{id_data}/\"\n",
    "    \n",
    "    # Convertir les paramètres en une chaîne JSON et les ajouter à l'URL\n",
    "    url += json.dumps(params)\n",
    "    \n",
    "    url += \"?withGeom=false\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = json.loads(response.content)\n",
    "        return pd.json_normalize(data['features'])\n",
    "    elif response.status_code == 401 or response.status_code == 401: \n",
    "        sys.exit(f\"Erreur: {response.status_code}\") \n",
    "    else:\n",
    "        print({response.status_code})\n",
    "        #sys.exit(f\"Erreur: {response.status_code}\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "82fe64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_to_database(data_dict, id_data):\n",
    "    \"\"\"\n",
    "    Add data to MongoDB collection based on id_data.\n",
    "    \n",
    "    Args:\n",
    "    - collection (pymongo.collection.Collection): MongoDB collection.\n",
    "    - data_dict (dict): Dictionary containing data to be added to the collection.\n",
    "    - id_data (int): Identifier of the data.\n",
    "    \"\"\"\n",
    "    if id_data == 112:\n",
    "        for entry in data_dict:\n",
    "            aire_quality.insert_one(entry)\n",
    "    elif id_data == 113 :\n",
    "        for entry in data_dict:\n",
    "            pollution_113.insert_one(entry)\n",
    "            \n",
    "    elif  id_data == 114:\n",
    "        for entry in data_dict:\n",
    "            pollution_114.insert_one(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "efcbe7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_trace_data_to_file(code_commune, id_data, start_date, trace_file):\n",
    "    \"\"\"\n",
    "    Writes information about commune without data to a trace file.\n",
    "    \n",
    "    Args:\n",
    "    - code_commune (int): Code of the commune.\n",
    "    - id_data (int): Identifier of the data.\n",
    "    - start_date (str): Start date in the format \"YYYY-MM-DD\".\n",
    "    - stop_date (str): Stop date in the format \"YYYY-MM-DD\".\n",
    "    - trace_file (str): Path to the CSV file to store the trace of communes without results.\n",
    "    \"\"\"\n",
    "    # Create DataFrame with trace data\n",
    "    trace_data = {\n",
    "        \"code_commune\": code_commune,\n",
    "        \"id_data\": id_data,\n",
    "        \"start_date\": start_date\n",
    "    }\n",
    "    trace_df = pd.DataFrame([trace_data])\n",
    "    \n",
    "    # Write trace data to CSV file\n",
    "    trace_df.to_csv(trace_file, mode=\"a\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "40f76503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_commune_data(commune_data, id_data):\n",
    "    \"\"\"\n",
    "    Clean commune data DataFrame by removing \"geometry\" column and renaming columns starting with \"properties.\".\n",
    "    \n",
    "    Args:\n",
    "    - commune_data (pd.DataFrame): DataFrame containing commune data.\n",
    "    - id_data (int): Identifier of the data.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    if id_data == 112:\n",
    "        # Drop the \"geometry\" column\n",
    "        commune_data.drop(columns=[\"geometry\"], inplace=True, errors=\"ignore\")\n",
    "        commune_data.drop(columns=[\"type\"], inplace=True, errors=\"ignore\")\n",
    "        # Rename columns starting with \"properties.\"\n",
    "        commune_data.rename(columns=lambda x: x.replace(\"properties.\", \"\"), inplace=True)\n",
    "        \n",
    "    else:\n",
    "        # Remove the \"type\" column\n",
    "        commune_data.drop(columns=[\"geometry\"], inplace=True, errors=\"ignore\")\n",
    "        commune_data.drop(columns=[\"type\"], inplace=True, errors=\"ignore\")\n",
    "        # Rename columns starting with \"properties.\"\n",
    "        commune_data.rename(columns=lambda x: x.replace(\"properties.\", \"\"), inplace=True)\n",
    "        \n",
    "    return commune_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35126d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b7be04b",
   "metadata": {},
   "source": [
    "## Fonctions principales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958d6b9",
   "metadata": {},
   "source": [
    "  The  *fetch_department* Fonction\n",
    "  \n",
    "  \"\"\"\n",
    "    Fetches air quality data for all communes in a specific department from the AtmoData API.\n",
    "    \n",
    "    Args:\n",
    "    - api_key (str): API key for authentication.\n",
    "    - id_data (int): Identifier of the data (112 for air quality indices).\n",
    "    - start_date (str): Start date in the format \"YYYY-MM-DD\".\n",
    "    - code_insee_file (str): Path to the Excel file containing commune codes INSEE and department codes.\n",
    "    - code_dept (int): Code of the department.\n",
    "    - trace_file (str): Path to the CSV file to store the trace of communes without results.\n",
    "    \n",
    "    Returns:\n",
    "    - void\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df28852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_department(api_key, id_data, start_date, code_insee_file, code_dept, trace_file):\n",
    "    # Read commune codes INSEE and department codes from the Excel file\n",
    "    df_communes = pd.read_excel(code_insee_file)\n",
    "    \n",
    "    # Filter communes for the specified department\n",
    "    dept_communes = df_communes[df_communes[\"DEP\"] == code_dept]\n",
    "        \n",
    "    # Iterate over all communes in the specified department\n",
    "    for _, commune in dept_communes.iterrows():\n",
    "        commune_code = commune[\"COM\"]\n",
    "        \n",
    "        # Define the parameters for the query\n",
    "        params = {\n",
    "            \"code_zone\": {\"operator\": \"=\", \"value\": commune_code},\n",
    "            \"date_ech\": {\"operator\": \">=\", \"value\": start_date}\n",
    "        }\n",
    "        \n",
    "        # Fetch data for the current commune\n",
    "        commune_data = fetch_atmo_data(api_key, id_data, params)\n",
    "        \n",
    "        # Append the data to the DataFrame\n",
    "        if commune_data is not None and not commune_data.empty:\n",
    "            commune_data = clean_commune_data(commune_data, id_data)\n",
    "            \n",
    "            #################################################################################\n",
    "            #Partie autres prétraitements avant enregistrements dans la bases. \n",
    "            # A revoir éventuellement (champs fortements corrélés, champ avec valeurs uniformes)\n",
    "            #################################################################################\n",
    "            \n",
    "            # add to database\n",
    "            add_data_to_database(commune_data.to_dict(orient='records'), id_data)\n",
    "            \n",
    "        else:\n",
    "            # Write trace data to file for commune without data\n",
    "            write_trace_data_to_file(commune_code, id_data, start_date, trace_file)\n",
    "            \n",
    "        # Remove the current commune from the DataFrame to ensure it's not processed again\n",
    "        df_communes = df_communes[df_communes[\"COM\"] != commune_code]\n",
    "    \n",
    "    # Load the Excel file as a template\n",
    "    wb = load_workbook(code_insee_file)\n",
    "    \n",
    "    # Select the active worksheet\n",
    "    ws = wb.active\n",
    "    \n",
    "    # Clear the existing data in the worksheet\n",
    "    for row in ws.iter_rows(min_row=2, max_col=ws.max_column, max_row=ws.max_row):\n",
    "        for cell in row:\n",
    "            cell.value = None\n",
    "    \n",
    "    # Write the modified DataFrame to the worksheet starting from the second row\n",
    "    for row_idx, row in enumerate(df_communes.values, start=2):\n",
    "        for col_idx, value in enumerate(row, start=1):\n",
    "            ws.cell(row=row_idx, column=col_idx, value=value)\n",
    "    \n",
    "    # Save the modified Excel file\n",
    "    wb.save(code_insee_file)\n",
    "    wb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1b5c33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_store(api_key, id_data, start_date, code_insee_file, trace_file):\n",
    "    \"\"\"\n",
    "    Fetches air quality data for all communes in France and stores it.\n",
    "    \n",
    "    Args:\n",
    "    - api_key (str): API key for authentication.\n",
    "    - id_data (int): Identifier of the data (112 for air quality indices).\n",
    "    - start_date (str): Start date in the format \"YYYY-MM-DD\".\n",
    "    - code_insee_file (str): Path to the Excel file containing commune codes INSEE and department codes.\n",
    "    - trace_file (str): Path to the CSV file to store the trace of communes without results.\n",
    "    \"\"\"\n",
    "    # Read commune codes INSEE and department codes from the Excel file\n",
    "    df_communes = pd.read_excel(code_insee_file)\n",
    "    \n",
    "    # Get unique department codes\n",
    "    dept_codes = df_communes[\"DEP\"].unique()\n",
    "    \n",
    "    # Iterate over all department codes\n",
    "    for code_dept in dept_codes:\n",
    "        # Fetch and process data for the current department\n",
    "        fetch_department(api_key, id_data, start_date, code_insee_file, code_dept, trace_file)\n",
    "        break;\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad37656",
   "metadata": {},
   "source": [
    "## Acquision des données selon divers paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457b371",
   "metadata": {},
   "source": [
    "Dans cette partie nous allons....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a7c9e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à la base de données MongoDB\n",
    "client = MongoClient('mongodb://localhost', 27017)\n",
    "db = client['climat_france'] \n",
    "aire_quality = db['aire_quality']\n",
    "pollution_113 = db['pollution_113']\n",
    "pollution_114 = db['pollution_114']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4fd88184",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data = 112 \n",
    "start_date = \"01-01-2023\"\n",
    "code_insee_file = \"commune_insee_112.xlsx\"\n",
    "trace_file = \"empty_trace_com.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b5b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{500}\n"
     ]
    }
   ],
   "source": [
    "# Call the function to fetch air quality data for the Paris region since the start of last year\n",
    "fetch_and_store(api_key, id_data, start_date, code_insee_file, trace_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e55cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21f04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
